import streamlit as st
import pandas as pd
import plotly.express as px
import numpy as np
import os
import fitz  # PyMuPDF ƒë·ªÉ ƒë·ªçc file PDF
import spacy
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
import random
from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas
import re
from datetime import datetime
import sqlite3
import hashlib
from sklearn.model_selection import KFold, cross_val_score, cross_val_predict
from sklearn.metrics import classification_report

# Load NLP model
nlp = spacy.load("en_core_web_sm")
# D·ªØ li·ªáu m·∫´u cho CV
names = ["Nguy·ªÖn Anh Tu·∫•n", "Tr·∫ßn VƒÉn A", "L√™ Th·ªã B", "Nguy·ªÖn Th·ªã C", "Phan ƒê·ª©c D",
         "L√™ Qu·ªëc ƒê·∫°t", "V√µ Th·ªã Ng·ªçc H∆∞∆°ng", "Ho√†ng Tr·ªçng Duy", "Ph·∫°m VƒÉn Th√†nh", "Nguy·ªÖn Thu H√†",
         "Tr·∫ßn Qu·ªëc V∆∞∆°ng", "ƒê·ªó Th·ªã Qu·ª≥nh Mai", "L√™ Minh Huy", "Ph·∫°m Ng·ªçc Kh√°nh", "Ho√†ng Th·ªã M·ªπ Linh",
         "L√™ Qu·ªëc ƒê·∫°t", "Tr·∫ßn Ho√†i Nam", "Nguy·ªÖn Thanh V≈©", "L√™ Th·ªã Mai Anh", "Ph·∫°m Minh Long",
         "Tr·∫ßn Quang Huy", "L√™ Ho√†ng Minh", "Nguy·ªÖn H·∫£i Y·∫øn", "Ph·∫°m VƒÉn H·∫£i", "Tr·∫ßn Th·ªã Mai Ph∆∞∆°ng",
         "Ho√†ng Minh Khang", "L√¢m Th·ªã Ng·ªçc Mai", "V≈© Th·ªã Hoa", "Tr·∫ßn Qu·ªëc B·∫£o", "Ph·∫°m Ng·ªçc Linh",
         "H·ªì Minh Qu√¢n", "Tr∆∞∆°ng VƒÉn B√¨nh", "ƒê·∫∑ng Minh H√πng", "Nguy·ªÖn H·∫£i Y·∫øn", "L√™ Thanh Tu·∫•n",
         "Nguy·ªÖn Duy Nam", "Ph·∫°m VƒÉn H·∫£i", "Tr·∫ßn Th·ªã Mai Ph∆∞∆°ng", "Ho√†ng Minh Khang", "B√ôI VƒÇN Q",
         "ƒê·∫∂NG TU·∫§N P", "Nguy·ªÖn Thanh S∆°n", "Chu Ti·∫øn Lu·∫≠t", "Nguy·ªÖn Ph∆∞∆°ng Nhi", "Nguy·ªÖn Quang H·∫£i",
         "Tr·ªãnh Tr·∫ßn Ph∆∞∆°ng Tu·∫•n", "Nguy·ªÖn Thanh T√πng", "Tr·∫ßn V≈©", "L√™ H·ªìng Ph√∫c", "Ph·∫°m Minh Tr√≠"]

cities = ["H·ªì Ch√≠ Minh", "H√† N·ªôi", "ƒê√† N·∫µng", "C·∫ßn Th∆°", "Nha Trang",
          "H√† N·ªôi", "ƒê√† N·∫µng", "TP. H·ªì Ch√≠ Minh", "H√† N·ªôi", "TP. H·∫£i Ph√≤ng",
          "TP. Nha Trang", "H√† N·ªôi", "TP. H·ªì Ch√≠ Minh", "TP. C·∫ßn Th∆°", "TP. H·ªì Ch√≠ Minh",
          "H√† N·ªôi", "TP. H·ªì Ch√≠ Minh", "TP. ƒê√† N·∫µng", "TP. ƒê√† N·∫µng", "TP. H·ªì Ch√≠ Minh",
          "TP. H√† N·ªôi", "TP. H·ªì Ch√≠ Minh", "Hu·∫ø", "H√† N·ªôi", "ƒê√† N·∫µng", "Phan Rang",
          "H√† N·ªôi", "ƒê√† L·∫°t", "H·∫£i Ph√≤ng", "H·ªì Ch√≠ Minh", "ƒê√† Nng", "ƒê√† L·∫°t", 
          "H√† N·ªôi", "ƒê·ªìng Nai", "B√¨nh D∆∞∆°ng", "Hu·∫ø", "C·∫ßn Th∆°", "T√¢y Ninh",
          "H·ªì Ch√≠ Minh", "H·∫£i Ph√≤ng", "ƒê√† N·∫µng", "H√† N·ªôi", "TP.HCM", "C·∫ßn Gi·ªù",
          "H√† N·ªôi", "Hu·∫ø", "Nha Trang", "Qu·∫£ng Ninh", "Ngh·ªá An", "Long An", "B√† R·ªãa"]

skills = ["Python, Java, SQL", "C#, JavaScript, HTML, CSS", "Node.js, React, MongoDB", "Java, Kotlin, Android", "Go, Ruby, Docker",
          "Java, .NET, Oracle Database", "Data Analysis", "AI, Machine Learning", "Blockchain, Smart Contracts", "Mobile Development",
          "MySQL, GoLang", "AI, TensorFlow", "Network Security, Python", "IoT, C++, Arduino", "Data Analysis, Tableau",
          "Java, .NET, Oracle Database", "Angular, Bootstrap", "Java, Spring Boot, Docker", "Java, Spring Boot, Docker", "Angular, Bootstrap",
          "JavaScript, Python, C++, Docker, Git, Jenkins", "DevOps, Docker, Jenkins", "Python, Java", "Big Data, Hadoop, Spark", "HTML, CSS, JavaScript, Vue.js",
          "JavaScript, TypeScript, Node.js", "Photoshop, Illustrator", "Articulate, Moodle", "React, Node.js, MongoDB", "Content Writing, Social Media",
          "Agile, Scrum", "Java, Go, Docker", "Flutter, Dart, Swift", "Python, Java", "SQL, Python, Tableau",
          "AWS, Azure, Docker, Kubernetes", "Big Data, Spark", "Frontend Development", "JavaScript, TypeScript, SQL", "Java, Spring Boot, MySQL"]

projects = ["H·ªá th·ªëng qu·∫£n l√Ω sinh vi√™n (2020)", "·ª®ng d·ª•ng di ƒë·ªông cho c√¥ng ty XYZ", "Website b√°n h√†ng tr·ª±c tuy·∫øn", "H·ªá th·ªëng theo d√µi s·ª©c kh·ªèe ng∆∞·ªùi d√πng", "·ª®ng d·ª•ng chatbot h·ªó tr·ª£ kh√°ch h√†ng",
            "·ª®ng d·ª•ng qu·∫£n l√Ω t√†i kho·∫£n ng√¢n h√†ng (2022)", "Ph√¢n t√≠ch d·ªØ li·ªáu kh√°ch h√†ng", "·ª®ng d·ª•ng AI trong s·∫£n xu·∫•t", "Smart Contract Platform", "·ª®ng d·ª•ng di ƒë·ªông th∆∞∆°ng m·∫°i",
            "H·ªá th·ªëng thanh to√°n tr·ª±c tuy·∫øn (2022)", "D·ª± ƒëo√°n b·ªánh d·ª±a tr√™n d·ªØ li·ªáu l·ªõn", "H·ªá th·ªëng ph√°t hi·ªán t·∫•n c√¥ng m·∫°ng", "H·ªá th·ªëng ƒëi·ªÅu khi·ªÉn ƒë√®n th√¥ng minh", "H·ªá th·ªëng d·ª± ƒëo√°n doanh thu",
            "·ª®ng d·ª•ng qu·∫£n l√Ω t√†i kho·∫£n ng√¢n h√†ng", "N·ªÅn t·∫£ng th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ ƒëa k√™nh", "H·ªá th·ªëng qu·∫£n l√Ω h·ªçc sinh", "H·ªá th·ªëng qu·∫£n l√Ω h·ªçc sinh", "N·ªÅn t·∫£ng th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ ƒëa k√™nh",
            "T·ªëi ∆∞u h√≥a tri·ªÉn khai ph·∫ßn m·ªÅm", "D·ª± √°n nghi√™n c·ª©u ML", "H·ªá th·ªëng ph√¢n t√≠ch d·ªØ li·ªáu kh√°ch h√†ng", "·ª®ng d·ª•ng qu·∫£n l√Ω b·ªánh vi·ªán",
            "H·ªá th·ªëng qu·∫£n l√Ω kho h√†ng (2022)", "Thi·∫øt k·∫ø logo v√† branding", "Kh√≥a h·ªçc K·ªπ nƒÉng m·ªÅm", "·ª®ng d·ª•ng qu·∫£n l√Ω b√°n h√†ng", "Chi·∫øn d·ªãch marketing s·ªë",
            "Qu·∫£n l√Ω d·ª± √°n ph·∫ßn m·ªÅm l·ªõn", "H·ªá th·ªëng qu·∫£n l√Ω nƒÉng l∆∞·ª£ng t√°i t·∫°o", "·ª®ng d·ª•ng qu·∫£n l√Ω l·ªãch tr√¨nh", "D·ª± √°n nghi√™n c·ª©u ML", "H·ªá th·ªëng d·ª± ƒëo√°n doanh thu ng√†nh b√°n l·∫ª",
            "H·ªá th·ªëng t·ª± ƒë·ªông tri·ªÉnn khai web", "Ph√¢n t√≠ch d·ªØ li·ªáu l·ªõn", "·ª®ng d·ª•ng qu·∫£n l√Ω b·ªánh vi·ªán", "H·ªá th·ªëng qu·∫£n l√Ω doanh nghi·ªáp", "H·ªá th·ªëng qu·∫£n l√Ω Java Enterprise"]

achievements = ["Gi·∫£i Nh·∫•t Hackathon 2021", "Nh√¢n vi√™n xu·∫•t s·∫Øc C√¥ng ty XYZ", "Gi·∫£i Ba cu·ªôc thi l·∫≠p tr√¨nh qu·ªëc gia", "Gi·∫£i Nh·∫•t cu·ªôc thi Code Wars",
                "Nh√¢n vi√™n xu·∫•t s·∫Øc nƒÉm 2021 t·∫°i Vietcombank", "Top 10 Data Analyst 2022", "Gi·∫£i nh·∫•t AI Challenge 2021", "Best Blockchain Developer 2022", "Mobile Developer of the Year",
                "Gi·∫£i th∆∞·ªüng S√°ng t·∫°o Tech 2022", "Ch·ª©ng nh·∫≠n TensorFlow Developer", "CEH Certification", "Cisco CCNA", "Tableau Specialist",
                "Nh√¢n vi√™n xu·∫•t s·∫Øc nƒÉm 2021", "Gi·∫£i Ba Hackathon 2021", "Google Cloud Certification", "AWS Certification", "Nh√¢n vi√™n xu·∫•t s·∫Øc 2022",
                "Gi·∫£i Nh√¨ Hackathon Cloud Computing 2020", "Top 3 Data Science Challenge", "Nh√¢n vi√™n ti√™u bi·ªÉu 2021", "Java Certification", "Google Analytics Certification",
                "PMP Certification", "Gi·∫£i th∆∞·ªüng s√°ng ki·∫øn c√¥ng ngh·ªá", "UI/UX Design Award", "Scrum Master Certification", "Digital Marketing Excellence",
                "Best Project Manager 2022"]

degrees = ["C·ª≠ nh√¢n C√¥ng ngh·ªá Th√¥ng tin", "C·ª≠ nh√¢n K·ªπ thu·∫≠t Ph·∫ßn m·ªÅm", "C·ª≠ nh√¢n Qu·∫£n tr·ªã Kinh doanh", "Th·∫°c sƒ© Khoa h·ªçc M√°y t√≠nh",
           "C·ª≠ nh√¢n H·ªá th·ªëng Th√¥ng tin Qu·∫£n l√Ω", "Th·∫°c sƒ© Khoa h·ªçc D·ªØ li·ªáu", "C·ª≠ nh√¢n Tr√≠ tu·ªá Nh√¢n t·∫°o", "C·ª≠ nh√¢n An to√†n Th√¥ng tin",
           "C·ª≠ nh√¢n IoT", "C·ª≠ nh√¢n Ph√¢n t√≠ch D·ªØ li·ªáu", "Th·∫°c sƒ© An to√†n Th√¥ng tin", "C·ª≠ nh√¢n K·ªπ thu·∫≠t M√°y t√≠nh",
           "C·ª≠ nh√¢n Khoa h·ªçc D·ªØ li·ªáu", "Th·∫°c sƒ© Tr√≠ tu·ªá Nh√¢n t·∫°o", "C·ª≠ nh√¢n C√¥ng ngh·ªá Ph·∫ßn m·ªÅm", "Th·∫°c sƒ© Khoa h·ªçc M√°y t√≠nh",
           "C·ª≠ nh√¢n H·ªá th·ªëng Th√¥ng tin", "C·ª≠ nh√¢n M·∫°ng m√°y t√≠nh", "Th·∫°c sƒ© K·ªπ thu·∫≠t Ph·∫ßn m·ªÅm", "C·ª≠ nh√¢n Khoa h·ªçc M√°y t√≠nh"]

emails = ["nguyen.tuan@example.com", "tran.a@example.com", "le.b@example.com", "nguyen.c@example.com", "phan.d@example.com",
          "lequocdat@example.com", "ngochuong@example.com", "trongduy@example.com", "vanthanh@example.com", "thuha@example.com",
          "quocvuong@example.com", "quynhmai@example.com", "minhhuy@example.com", "ngockhanh@example.com", "mylinh@example.com",
          "lequocdat@example.com", "hoainam@example.com", "thanhvu@example.com", "maianh@example.com", "minhlong@example.com",
          "quanghuy@example.com", "hoangminh@example.com", "haiyen@example.com", "vanhai@example.com", "maiphuong@example.com",
          "minhkhang@example.com", "ngocmai@example.com", "thihoa@example.com", "quocbao@example.com", "ngoclinh@example.com",
          "minhquan@example.com", "vanbinh@example.com", "minhhung@example.com", "haiyen@example.com", "thanhtuan@example.com",
          "duynam@example.com", "vanhai@example.com", "maiphuong@example.com", "minhkhang@example.com", "buiq@example.com"]

phones = ["0987654321", "0912345678", "0909876543", "0981234567", "0918765432",
          "0912456789", "0909123456", "0908234567", "0907345678", "0906456789",
          "0905567890", "0987345678", "0912987654", "0909123456", "0908765432",
          "0912456789", "0909876543", "0979123456", "0979123456", "0909876543",
          "0987654321", "0988123456", "0908776654", "0911223344", "0933445566",
          "0922334455", "0905777766", "0912345678", "0988112233", "0905123456",
          "0938778889", "0975223344", "0988332211", "0908776654", "0938776543",
          "0909776655", "0911223344", "0933445566", "0922334455", "0907654321",
          "0901231234", "0923323123", "0921837123", "0912312313", "0921321731"]

# H√†m t·∫°o CV ng·∫´u nhi√™n
def generate_cv():
    name = random.choice(names)
    city = random.choice(cities)
    email = random.choice(emails)
    phone = random.choice(phones)
    skill = random.choice(skills)
    project = random.choice(projects)
    achievement = random.choice(achievements)
    degree = random.choice(degrees)
    
    cv_text = f"""
    {name}
    {city}, Vi·ªát Nam
    Email: {email}
    S·ªë ƒëi·ªán tho·∫°i: {phone}
    
    M·ª§C TI√äU NGH·ªÄ NGHI·ªÜP
    L·∫≠p tr√¨nh vi√™n v·ªõi 8 nƒÉm kinh nghi·ªám trong ph√°t tri·ªÉn ph·∫ßn m·ªÅm, ƒë·∫∑c bi·ªát l√† x√¢y d·ª±ng c√°c ·ª©ng d·ª•ng web v√† h·ªá th·ªëng ph√¢n t√°n. T√¥i lu√¥n t√¨m ki·∫øm th·ª≠ th√°ch m·ªõi v√† c∆° h·ªôi ƒë·ªÉ h·ªçc h·ªèi, nh·∫±m nng cao k·ªπ nƒÉng v√† ƒë√≥ng g√≥p cho s·ª± ph√°t tri·ªÉn c·ªßa doanh nghi·ªáp.

    KINH NGHI·ªÜM L√ÄM VI·ªÜC
    2019 - Nay | C√¥ng ty XYZ | L·∫≠p tr√¨nh vi√™n ch√≠nh
    ‚Ä¢ Tham gia thi·∫øt k·∫ø v√† ph√°t tri·ªÉn ·ª©ng d·ª•ng qu·∫£n l√Ω d·ª± √°n cho doanh nghi·ªáp.
    ‚Ä¢ L√†m vi·ªác v·ªõi nh√≥m ƒë·ªÉ c·∫£i thi·ªán quy tr√¨nh ph√°t tri·ªÉn ph·∫ßn m·ªÅm.
    2017 - 2019 | C√¥ng ty 123 | L·∫≠p tr√¨nh vi√™n
    ‚Ä¢ Ph√°t tri·ªÉn c√°c API backend cho ·ª©ng d·ª•ng di ƒë·ªông.
    ‚Ä¢ ƒê·∫£m b·∫£o t√≠nh b·∫£o m·∫≠t v√† hi·ªáu su·∫•t c·ªßa h·ªá th·ªëng.

    H·ªåC V·∫§N
    2013 - 2017 | ƒê·∫°i h·ªçc FPT | {degree}
    ‚Ä¢ GPA: 3.7/4.0
    ‚Ä¢ C√°c m√¥n h·ªçc ch√≠nh: Ph√°t tri·ªÉn ph·∫ßn m·ªÅm, C∆° s·ªü d·ªØ li·ªáu, An ninh m·∫°ng.

    K·ª∏ NƒÇNG
    ‚Ä¢ {skill}

    CH·ª®NG CH·ªà
    ‚Ä¢ Ch·ª©ng ch·ªâ AWS Certified Developer ‚Äì Associate
    ‚Ä¢ Ch·ª©ng ch·ªâ Google Cloud Professional Cloud Architect

    TH√ÄNH T√çCH
    ‚Ä¢ {achievement}
    ‚Ä¢ ƒê∆∞·ª£c c√¥ng nh·∫≠n l√† "Nh√¢n vi√™n xu·∫•t s·∫Øc" t·∫°i C√¥ng ty XYZ

    D·ª∞ √ÅN
    {project}
    ‚Ä¢ X√¢y d·ª±ng h·ªá th·ªëng qu·∫£n l√Ω th√¥ng tin sinh vi√™n cho tr∆∞·ªùng ƒë·∫°i h·ªçc.
    ‚Ä¢ C√¥ng ngh·ªá: React, Express.js, MySQL

    NG√îN NG·ªÆ
    ‚Ä¢ Ti·∫øng Vi·ªát: Ng∆∞·ªùi b·∫£n x·ª©
    ‚Ä¢ Ti·∫øng Anh: Th√†nh th·∫°o

    S·ªû TH√çCH
    ‚Ä¢ Ch·∫°y marathon
    ‚Ä¢ T√¨m hi·ªÉu v·ªÅ tr√≠ tu·ªá nh√¢n t·∫°o

    Lƒ®NH V·ª∞C QUAN T√ÇM
    ‚Ä¢ C√¥ng ngh·ªá blockchain
    """
    
    return cv_text

# H√†m t·∫°o PDF t·ª´ n·ªôi dung CV
def generate_pdf(cv_text, file_name):
    c = canvas.Canvas(file_name, pagesize=letter)
    text_object = c.beginText(40, 750)
    text_object.setFont("Helvetica", 10)
    
    for line in cv_text.split("\n"):
        text_object.textLine(line)
    
    c.drawText(text_object)
    c.save()

    
# Danh s√°ch k·ªπ nƒÉng ph·ªï bi·∫øn
SKILLS_KEYWORDS = [
    # Programming Languages
    "python", "javascript", "sql", "java", "c++", "c#", "php", "ruby", "swift",
    "typescript", "kotlin", "go", "rust", "scala", "r", "matlab", "perl",
    "objective-c", "dart", "lua", "haskell", "assembly",

    # Frameworks & Libraries
    "react", "node.js", "angular", "vue.js", "django", "flask", "spring", "express.js",
    "laravel", "asp.net", "ruby on rails", "jquery", "bootstrap", "tailwind",
    "next.js", "nuxt.js", "flutter", "react native", "xamarin", "tensorflow",
    "pytorch", "keras", "pandas", "numpy", "scikit-learn", "redux", "graphql",

    # Cloud & DevOps
    "aws", "azure", "gcp", "docker", "kubernetes", "jenkins", "git",
    "terraform", "ansible", "puppet", "chef", "circleci", "travis ci",
    "github actions", "bitbucket", "gitlab", "nginx", "apache", "linux",
    "windows server", "bash", "shell scripting", "powershell",

    # Big Data & AI
    "hadoop", "spark", "big data", "machine learning", "ai", "deep learning",
    "data mining", "data science", "natural language processing", "computer vision",
    "neural networks", "reinforcement learning", "data analytics", "tableau",
    "power bi", "elasticsearch", "kafka", "airflow", "databricks",

    # Databases
    "mysql", "mongodb", "postgresql", "firebase", "oracle",
    "sql server", "redis", "cassandra", "dynamodb", "mariadb",
    "neo4j", "sqlite", "couchdb", "influxdb", "elasticsearch",

    # Frontend
    "html", "css", "sass", "less", "webpack", "babel", "responsive design",
    "web accessibility", "seo", "pwa", "web components", "material ui",
    "ant design", "chakra ui", "styled components",

    # Backend
    "rest api", "soap", "microservices", "websocket", "grpc", "oauth",
    "jwt", "api gateway", "load balancing", "caching", "message queues",
    "rabbitmq", "redis", "memcached",

    # Testing
    "unit testing", "integration testing", "selenium", "jest", "mocha",
    "cypress", "junit", "pytest", "testng", "cucumber", "postman",

    # Methodologies & Practices
    "scrum", "agile", "waterfall", "kanban", "lean", "tdd", "bdd",
    "ci/cd", "devops", "itil", "solid principles", "design patterns",
    "mvc", "mvvm", "clean architecture", "CI/CD ",

    # Security
    "cybersecurity", "encryption", "oauth", "jwt", "ssl/tls",
    "penetration testing", "security audit", "firewall", "vpn",

    # Mobile Development
    "ios", "android", "react native", "flutter", "xamarin",
    "swift ui", "kotlin multiplatform", "mobile security",

    # Version Control
    "git", "svn", "mercurial", "github", "gitlab", "bitbucket",
    "git flow", "trunk based development",

    # Project Management
    "jira", "trello", "asana", "confluence", "notion",
    "microsoft project", "basecamp",

    # Additional Skills
    "blockchain", "ethereum", "smart contracts", "solidity",
    "ar/vr", "unity", "unreal engine", "webgl", "three.js",
    "iot", "embedded systems", "raspberry pi", "arduino"
    
]

# D·ªØ li·ªáu m·∫´u m·ªõi cho c√°c c·∫•p ƒë·ªô ·ª©ng vi√™n
X = np.array([
    # Fresher (0-2 years, 3-10 skills)
    [0, 5], [1, 7], [2, 8], [0, 3], [1, 6], [2, 9], [0, 4], [1, 8],
    # Junior (2-3 years, 8-15 skills)
    [2, 10], [3, 12], [2, 14], [3, 13], [2, 11], [3, 15], [2, 8], [3, 9],
    # Middle (3-6 years, 15-25 skills)
    [4, 18], [5, 20], [6, 22], [3, 15], [4, 17], [5, 23], [6, 25], [4, 16],
    # Senior (7+ years, 20-40 skills)
    [7, 30], [8, 35], [9, 40], [7, 25], [8, 28], [9, 38], [7, 22], [8, 32]
])

y = (
    ['Fresher'] * 8 +
    ['Junior'] * 8 +
    ['Middle'] * 8 +
    ['Senior'] * 8
)

# 1. Kh·ªüi t·∫°o c√°c bi·∫øn global cho model
model = RandomForestClassifier(random_state=42)  # Model ph√¢n lo·∫°i Random Forest
k_folds = 5  # S·ªë l∆∞·ª£ng fold cho cross-validation
kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)  # Kh·ªüi t·∫°o K-Fold

# 2. H√†m kh·ªüi t·∫°o v√† hu·∫•n luy·ªán model
def init_model():
    """
    Kh·ªüi t·∫°o v√† hu·∫•n luy·ªán model RandomForest
    Returns:
        model: Model ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán v·ªõi d·ªØ li·ªáu X, y
    """
    global model
    model.fit(X, y)
    return model

# 3. H√†m ƒë√°nh gi√° hi·ªáu su·∫•t model
def evaluate_model():
    """
    ƒê√°nh gi√° hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh b·∫±ng K-fold Cross Validation
    
    Hi·ªÉn th·ªã:
    - ƒêi·ªÉm ch√≠nh x√°c cho t·ª´ng l·∫ßn chia d·ªØ li·ªáu
    - ƒê·ªô ch√≠nh x√°c trung b√¨nh v√† ƒë·ªô l·ªách chu·∫©n
    - B√°o c√°o chi ti·∫øt v·ªÅ ph√¢n lo·∫°i
    - Bi·ªÉu ƒë·ªì h·ªôp c·ªßa c√°c ƒëi·ªÉm s·ªë
    """
    global model, kf
    st.subheader("üìä ƒê√°nh gi√° m√¥ h√¨nh v·ªõi K-fold Cross Validation")
    
    # T√≠nh accuracy scores cho t·ª´ng fold
    scores = cross_val_score(model, X, y, cv=kf)
    
    # D·ª± ƒëo√°n nh√£n cho to√†n b·ªô dataset
    y_pred = cross_val_predict(model, X, y, cv=kf)
    
    # Hi·ªÉn th·ªã k·∫øt qu·∫£ chi ti·∫øt t·ª´ng fold
    st.write(f"S·ªë fold: {k_folds}")
    for i, score in enumerate(scores, 1):
        st.write(f"Fold {i}: {score:.2%}")
    
    # Hi·ªÉn th·ªã metrics t·ªïng qu√°t
    st.write(f"ƒê·ªô ch√≠nh x√°c trung b√¨nh: {scores.mean():.2%} (¬±{scores.std()*2:.2%})")
    
    # Hi·ªÉn th·ªã b√°o c√°o ph√¢n lo·∫°i chi ti·∫øt
    st.write("Chi ti·∫øt ƒë√°nh gi√°:")
    report = classification_report(y, y_pred)
    st.code(report)
    
    # V·∫Ω boxplot cho scores
    fig, ax = plt.subplots()
    ax.boxplot(scores)
    ax.set_title('K-fold Cross Validation Scores')
    ax.set_ylabel('Accuracy')
    st.pyplot(fig)

# 4. H√†m hu·∫•n luy·ªán model cu·ªëi c√πng
def train_final_model():
    """
    Hu·∫•n luy·ªán model cu·ªëi c√πng tr√™n to√†n b·ªô dataset
    Returns:
        model: Model ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán
    """
    global model
    model.fit(X, y)
    return model

# 5. Kh·ªüi t·∫°o session state cho model
if 'trained_model' not in st.session_state:
    st.session_state['trained_model'] = train_final_model()

# 6. H√†m ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng CV
def analyze_cv_quality(cv_text, skills, years_exp):
    """
    Ph√¢n t√≠ch v√† ch·∫•m ƒëi·ªÉm CV d·ª±a tr√™n 3 ti√™u ch√≠ ch√≠nh
    
    Tham s·ªë:
        cv_text (str): N·ªôi dung CV ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
        skills (list): Danh s√°ch c√°c k·ªπ nƒÉng ƒë∆∞·ª£c tr√≠ch xu·∫•t
        years_exp (int): S·ªë nƒÉm kinh nghi·ªám
        
    Tr·∫£ v·ªÅ:
        tuple: G·ªìm 2 ph·∫ßn t·ª≠:
            - quality_score (int): T·ªïng ƒëi·ªÉm CV (t·ªëi ƒëa 85)
            - feedback (list): Danh s√°ch c√°c nh·∫≠n x√©t chi ti·∫øt
    
    Thang ƒëi·ªÉm:
        - Kinh nghi·ªám: 30ƒë (5+ nƒÉm: 30ƒë, 3-5 nƒÉm: 20ƒë, 1-3 nƒÉm: 10ƒë)
        - K·ªπ nƒÉng: 25ƒë (15+ k·ªπ nƒÉng: 25ƒë, 8-14 k·ªπ nƒÉng: 15ƒë)
        - Ch·ª©ng ch·ªâ & th√†nh t√≠ch: 30ƒë (m·ªói m·ª•c 15ƒë)
    """
    quality_score = 0
    feedback = []
    
    # 1. ƒê√°nh gi√° kinh nghi·ªám (30ƒë)
    if years_exp >= 5:
        quality_score += 30
        feedback.append("‚úÖ Kinh nghi·ªám l√†m vi·ªác phong ph√∫")
    elif years_exp >= 3:
        quality_score += 20
        feedback.append("‚úÖ C√≥ kinh nghi·ªám l√†m vi·ªác t·ªët")
    elif years_exp >= 1:
        quality_score += 10
        feedback.append("‚ö†Ô∏è Kinh nghi·ªám c√≤n h·∫°n ch·∫ø")
    
    # 2. ƒê√°nh gi√° k·ªπ nƒÉng (25ƒë)
    if len(skills) >= 15:
        quality_score += 25
        feedback.append("‚úÖ C√≥ nhi·ªÅu k·ªπ nƒÉng chuy√™n m√¥n")
    elif len(skills) >= 8:
        quality_score += 15
        feedback.append("‚úÖ C√≥ ƒë·ªß k·ªπ nƒÉng c∆° b·∫£n")
    else:
        feedback.append("‚ö†Ô∏è C·∫ßn b·ªï sung th√™m k·ªπ nƒÉng")
    
    # 3. ƒê√°nh gi√° ch·ª©ng ch·ªâ v√† th√†nh t√≠ch (30ƒë)
    if "ch·ª©ng ch·ªâ" in cv_text.lower():
        quality_score += 15
        feedback.append("‚úÖ C√≥ ch·ª©ng ch·ªâ chuy√™n m√¥n")
    if "gi·∫£i" in cv_text.lower() or "th√†nh t√≠ch" in cv_text.lower():
        quality_score += 15
        feedback.append("‚úÖ C√≥ th√†nh t√≠ch n·ªïi b·∫≠t")
    
    return quality_score, feedback

def predict_candidate_level(years_of_experience, num_skills, trained_model, cv_text):
    """D·ª± ƒëo√°n c·∫•p ƒë·ªô ·ª©ng vi√™n v·ªõi ƒë·ªô tin c·∫≠y c·∫£i ti·∫øn"""
    features = np.array([[years_of_experience, num_skills]])
    prediction = trained_model.predict(features)[0]
    probabilities = trained_model.predict_proba(features)[0]
    base_confidence = max(probabilities) * 100
    
    # T√≠nh ƒëi·ªÉm ch·∫•t l∆∞·ª£ng CV
    skills = extract_skills_with_spacy(cv_text)  # Tr√≠ch xu·∫•t skills t·ª´ cv_text
    quality_score, feedback = analyze_cv_quality(cv_text, skills, years_of_experience)
    
    # ƒêi·ªÅu ch·ªânh ƒë·ªô tin c·∫≠y d·ª±a tr√™n ch·∫•t l∆∞·ª£ng CV
    confidence_boost = quality_score * 0.3  # 30% c·ªßa ƒëi·ªÉm ch·∫•t l∆∞·ª£ng
    final_confidence = min(base_confidence + confidence_boost, 95)
    
    return prediction, final_confidence, feedback

# 7. extract_years_of_experience 
def extract_years_of_experience(text):
    try:
        text = text.lower()
        current_year = datetime.now().year
        total_years = 0
        # T√¨m v·ªã tr√≠ ph·∫ßn kinh nghi·ªám trong CV
        start_index = text.find("kinh nghi·ªám l√†m vi·ªác")
        if start_index == -1:
            start_index = text.find("experience")
        # T√¨m ƒëi·ªÉm k·∫øt th√∫c c·ªßa ph·∫ßn kinh nghi·ªám
        end_index = text.find("k·ªπ nƒÉng")
        if end_index == -1:
            end_index = text.find("skills")
            
        if start_index != -1 and end_index != -1:
            exp_section = text[start_index:end_index]
            # T√¨m kinh nghi·ªám hi·ªán t·∫°i (ƒë·∫øn nay)
            current_matches = re.findall(r'(20\d{2})\s*-\s*(nay|present)', exp_section)
            if current_matches:
                start_year = int(current_matches[0][0])
                total_years += current_year - start_year
            # T√¨m c√°c kho·∫£ng th·ªùi gian l√†m vi·ªác trong qu√° kh·ª©
            past_matches = re.findall(r'(20\d{2})\s*-\s*(20\d{2})', exp_section)
            for start_year, end_year in past_matches:
                total_years += int(end_year) - int(start_year)
            
            if total_years > 0:
                return total_years
         # Logic d·ª± ph√≤ng: ∆∞·ªõc t√≠nh kinh nghi·ªám d·ª±a tr√™n s·ªë l∆∞·ª£ng k·ªπ nƒÉng
        skills = extract_skills_with_spacy(text)
        num_skills = len(skills)
        if num_skills >= 8: return 7
        elif num_skills >= 5: return 4
        elif num_skills >= 3: return 2
        else: return 1
        
    except Exception as e:
        st.error(f"L·ªói khi tr√≠ch xu·∫•t kinh nghi·ªám: {str(e)}")
        return 1
# 8. T√≠nh ƒë·ªô tin c·∫≠y
def calculate_confidence(cv_text, skills, years_exp):
    """
    T√≠nh ƒë·ªô tin c·∫≠y c·ªßa vi·ªác ƒë√°nh gi√° CV
    
    Tham s·ªë:
        cv_text (str): N·ªôi dung CV
        skills (list): Danh s√°ch k·ªπ nƒÉng
        years_exp (int): S·ªë nƒÉm kinh nghi·ªám
        
    Tr·∫£ v·ªÅ:
        float: ƒê·ªô tin c·∫≠y c·ªßa ƒë√°nh gi√° (0-100%)
    """
    confidence = 0
    feedback = []
    
    # Ki·ªÉm tra nƒÉm kinh nghi·ªám (25%)
    if years_exp is not None:
        confidence += 25
        feedback.append("‚úÖ X√°c ƒë·ªãnh ƒë∆∞·ª£c s·ªë nƒÉm kinh nghi·ªám")
    else:
        feedback.append("‚ùå Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c s·ªë nƒÉm kinh nghi·ªám")

    # Ki·ªÉm tra k·ªπ nƒÉng (25%)
    if len(skills) > 0:
        confidence += 25
        feedback.append(f"‚úÖ X√°c ƒë·ªãnh ƒë∆∞·ª£c {len(skills)} k·ªπ nƒÉng")
    else:
        feedback.append("‚ùå Kh√¥ng t√¨m th·∫•y k·ªπ nƒÉng")

    # Ki·ªÉm tra c√°c ph·∫ßn ch√≠nh (25%)
    required_sections = [
        "m·ª•c ti√™u ngh·ªÅ nghi·ªáp",
        "h·ªçc v·∫•n",
        "kinh nghi·ªám l√†m vi·ªác",
        "k·ªπ nƒÉng",
        "d·ª± √°n",
        "ch·ª©ng ch·ªâ",
        "th√†nh t√≠ch",
        "s·ªü th√≠ch",
        "lƒ©nh v·ª±c quan t√¢m"
    ]
    
    sections_found = sum(1 for section in required_sections 
                        if section in cv_text.lower())
    section_score = (sections_found / len(required_sections)) * 25
    confidence += section_score
    
    if sections_found == len(required_sections):
        feedback.append("‚úÖ CV c√≥ ƒë·∫ßy ƒë·ªß t·∫•t c·∫£ c√°c ph·∫ßn")
    else:
        missing = [s for s in required_sections 
                  if s not in cv_text.lower()]
        feedback.append(f"‚ÑπÔ∏è CV c√≥ {sections_found}/{len(required_sections)} ph·∫ßn")

    # Ki·ªÉm tra t√≠nh nh·∫•t qu√°n c·ªßa th√¥ng tin (25%)
    consistency_score = 0
    
    # M·ª•c ti√™u ph√π h·ª£p v·ªõi kinh nghi·ªám v√† k·ªπ nƒÉng
    if any(keyword in cv_text.lower() for keyword in ["ai", "machine learning"]):
        consistency_score += 10
    
    # C√≥ ch·ª©ng ch·ªâ ho·∫∑c th√†nh t√≠ch
    if "ch·ª©ng ch·ªâ" in cv_text.lower() or "th√†nh t√≠ch" in cv_text.lower():
        consistency_score += 15
    
    confidence += consistency_score

    confidence_level = ""
    if confidence >= 90:
        confidence_level = "R·∫•t cao"
    elif confidence >= 75:
        confidence_level = "Cao"
    elif confidence >= 60:
        confidence_level = "Kh√°"
    elif confidence >= 40:
        confidence_level = "Trung b√¨nh"
    else:
        confidence_level = "Th·∫•p"

    return {
        "score": round(confidence, 1),  # L√†m tr√≤n ƒë·∫øn 1 ch·ªØ s·ªë th·∫≠p ph√¢n
        "level": confidence_level,
        "feedback": feedback
    }

RECOMMENDED_SECTIONS = [
    "M·ª•c ti√™u ngh·ªÅ nghi·ªáp", "H·ªçc v·∫•n", "Kinh nghi·ªám l√†m vi·ªác", "K·ªπ nƒÉng",
    "D·ª± √°n", "Ch·ª©ng ch·ªâ", "Th√†nh t√≠ch", "S·ªü th√≠ch", "Lƒ©nh v·ª±c quan t√¢m"
]

# Admin login function
def admin_login():
    if 'logged_in' not in st.session_state:
        st.session_state.logged_in = False
        
    if not st.session_state.logged_in:
        admin_user = st.text_input("Username")
        admin_password = st.text_input("Password", type='password')
        
        if st.button('Login'):
            conn = init_db()
            c = conn.cursor()
            c.execute('SELECT password_hash FROM admin WHERE username = ?', (admin_user,))
            result = c.fetchone()
            
            if result and result[0] == hashlib.sha256(admin_password.encode()).hexdigest():
                st.session_state.logged_in = True
                st.success("Welcome to the Admin Side")
                st.rerun()
            else:
                st.error("Invalid credentials")
            conn.close()
            return False
    return True

def init_db():
    conn = sqlite3.connect('cv_database.db')
    c = conn.cursor()
    
    c.execute('''
        CREATE TABLE IF NOT EXISTS cv_data
        (id INTEGER PRIMARY KEY AUTOINCREMENT,
         cv_text TEXT,
         skills TEXT,
         level TEXT,
         score REAL,
         submit_date DATETIME,
         sections TEXT)
    ''')
    
    c.execute('''
        CREATE TABLE IF NOT EXISTS admin
        (username TEXT PRIMARY KEY,
         password_hash TEXT)
    ''')
    
    admin_pass_hash = hashlib.sha256('123'.encode()).hexdigest()
    c.execute('INSERT OR REPLACE INTO admin VALUES (?, ?)', ('a', admin_pass_hash))
    
    conn.commit()
    return conn

def save_cv_data(cv_data):
    try:
        conn = init_db()
        c = conn.cursor()
        
        cv_text = cv_data['cv_text'][0]
        skills = ','.join(cv_data['skills'][0]) if isinstance(cv_data['skills'][0], list) else cv_data['skills'][0]
        level = cv_data['level'][0]
        score = cv_data['score'][0]
        submit_date = datetime.now()
        sections = str(cv_data)
        
        c.execute('''
            INSERT INTO cv_data 
            (cv_text, skills, level, score, submit_date, sections)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (cv_text, skills, level, score, submit_date, sections))
        
        conn.commit()
        conn.close()
    except Exception as e:
        st.error(f"Error saving CV data: {str(e)}")

def load_cv_data():
    try:
        conn = init_db()
        query = "SELECT * FROM cv_data"
        df = pd.read_sql_query(query, conn)
        conn.close()
        return df
    except Exception as e:
        st.error(f"Error loading CV data: {str(e)}")
        return pd.DataFrame()

# Function to display pie charts
def display_pie_chart(data, column_name, title):
    if column_name in data.columns:
        counts = data[column_name].value_counts()
        fig = px.pie(values=counts, names=counts.index, title=title)
        st.plotly_chart(fig)
    else:
        st.warning(f"Column {column_name} not found in the data.")

# Extract text from PDF file
def extract_text_from_pdf(pdf_file):
    try:
        doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
        text = ""
        for page in doc:
            text += page.get_text()
        return text.strip()
    except Exception as e:
        return f"Kh√¥ng th·ªÉ ƒë·ªçc file PDF. L·ªói: {e}"

# Extract skills from text using Spacy NLP
def extract_skills_with_spacy(text):
    """C·∫£i thi·ªán vi·ªác tr√≠ch xu·∫•t k·ªπ nƒÉng"""
    doc = nlp(text.lower())
    skills_found = []
    
    # Th√™m c√°c t·ª´ kh√≥a ƒë·∫∑c bi·ªát cho mobile development
    mobile_keywords = {
        "ios", "android", "flutter", "react native", "swift", "kotlin", "dart",
        "mobile development", "xcode", "android studio", "firebase", "ui/ux",
        "rest api", "mvvm", "mvc", "core data", "realm", "sqlite"
    }
    
    # Single token skills
    for token in doc:
        if token.text in SKILLS_KEYWORDS or token.text in mobile_keywords:
            skills_found.append(token.text)
    
    # Multi-token skills
    for skill in SKILLS_KEYWORDS + list(mobile_keywords):
        if ' ' in skill and skill in text.lower():
            skills_found.append(skill)
            
    return list(set(skills_found))

# Check missing sections in CV content
def check_missing_sections(content):
    missing_sections = []
    for section in RECOMMENDED_SECTIONS:
        if section.lower() not in content.lower():
            missing_sections.append((section, "‚ùå"))
        else:
            missing_sections.append((section, "‚úîÔ∏è"))
    return missing_sections

# Extract CV sections
def extract_cv_sections(content):
    sections = {
        "M·ª•c ti√™u ngh·ªÅ nghi·ªáp": None,
        "H·ªçc v·∫•n": None,
        "Kinh nghi·ªám l√†m vi·ªác": None,
        "K·ªπ nƒÉng": None,
        "D·ª± √°n": None,
        "Ch·ª©ng ch·ªâ": None,
        "Th√†nh t√≠ch": None,
        "S·ªü th√≠ch": None,
        "Lƒ©nh v·ª±c quan t√¢m": None
    }
    
    for section in sections.keys():
        section_start = content.lower().find(section.lower())
        if section_start != -1:
            section_end = content.lower().find("\n", section_start + len(section))
            sections[section] = content[section_start:section_end].strip() if section_end != -1 else content[section_start:].strip()

    return sections

# Main User view
st.set_page_config(page_title="AI CV Analysis", layout="wide")

role = st.sidebar.selectbox("Ch·ªçn vai tr√≤", ["User", "Admin"])

if role == "User":
    st.title("üéØ AI CV Analysis")
    st.markdown("""
    <style>
    .big-font {
        font-size:20px !important;
        color: #1E88E5;
    }
    .stButton>button {
        background-color: #1E88E5;
        color: white;
        border-radius: 5px;
    }
    .stProgress .st-bo {
        background-color: #4CAF50;
    }
    .css-1v0mbdj.etr89bj1 {
        border-radius: 10px;
        padding: 20px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .stTab {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
    }
    </style>
    """, unsafe_allow_html=True)
    
    st.markdown('<p class="big-font">H·ªá th·ªëng ph√¢n t√≠ch v√† ƒë√°nh gi√° CV th√¥ng minh</p>', unsafe_allow_html=True)
    
    col1, col2 = st.columns([2,1])
    with col1:
        st.markdown("""
        ### üöÄ T√≠nh nƒÉng ch√≠nh:
        - ‚ú® Ph√¢n t√≠ch chi ti·∫øt n·ªôi dung CV
        - üìä ƒê√°nh gi√° ƒëi·ªÉm s·ªë chuy√™n nghi·ªáp
        - üí° G·ª£i √Ω c·∫£i thi·ªán c·ª• th·ªÉ
        - üéØ X√°c ƒë·ªãnh c·∫•p ƒë·ªô ·ª©ng vi√™n
        - üìà ƒê·ªÅ xu·∫•t k·ªπ nƒÉng c·∫ßn ph√°t tri·ªÉn
        """)
    with col2:
        st.image("https://img.freepik.com/free-vector/cv-template-minimalist-style_23-2148911517.jpg", width=200)
    
    st.markdown("---")
    st.subheader("üìÑ T·∫£i CV c·ªßa b·∫°n")
    # Upload nhi·ªÅu file
    uploaded_files = st.file_uploader("Ch·ªçn c√°c t·ªáp PDF c·ªßa b·∫°n", type=["pdf"], accept_multiple_files=True)

    if uploaded_files:
        # T·∫°o dictionary ƒë·ªÉ l∆∞u th√¥ng tin c·ªßa t·ª´ng CV
        cv_data_dict = {}
        
        # X·ª≠ l√Ω t·ª´ng file ƒë∆∞·ª£c upload
        for file in uploaded_files:
            cv_text = extract_text_from_pdf(file)
            cv_data_dict[file.name] = {
                'content': cv_text,
                'skills': extract_skills_with_spacy(cv_text),
                'num_pages': len(cv_text) // 1000 + 1
            }
        
        # T·∫°o selectbox ƒë·ªÉ ch·ªçn CV
        selected_cv = st.selectbox(
            "Ch·ªçn CV ƒë·ªÉ xem chi ti·∫øt:",
            options=list(cv_data_dict.keys())
        )
        
        # Hi·ªÉn th·ªã th√¥ng tin c·ªßa CV ƒë∆∞·ª£c ch·ªçn
        if selected_cv:
            cv_info = cv_data_dict[selected_cv]
            content = cv_info['content']
            skills = cv_info['skills']
            num_pages = cv_info['num_pages']
            
            # Hi·ªÉn th·ªã n·ªôi dung CV
            st.subheader("N·ªôi dung CV ƒë∆∞·ª£c ch·ªçn:")
            st.text_area("N·ªôi dung CV", content, height=200)
            
            # Hi·ªÉn th·ªã k·ªπ nƒÉng
            st.subheader("K·ªπ nƒÉng tr√≠ch xu·∫•t t·ª´ CV:")
            if skills:
                st.markdown(", ".join([f"`{skill}`" for skill in skills]))
            else:
                st.warning("Kh√¥ng t√¨m th·∫•y k·ªπ nƒÉng n√†o trong CV.")
            
            # X√°c ƒë·ªãnh c·∫•p ƒë·ªô
            years_exp = extract_years_of_experience(content)
            level, confidence, feedback = predict_candidate_level(
                years_exp, 
                len(skills),
                st.session_state['trained_model'],
                content
            )
            
            st.subheader("Ph√¢n t√≠ch CV:")
            st.write(f"**C·∫•p ƒë·ªô:** {level}")
            st.write(f"**ƒê·ªô tin c·∫≠y:** {confidence:.1f}%")

            st.write("**ƒê√°nh gi√° chi ti·∫øt:**")
            for item in feedback:
                st.write(item)

            if confidence < 60:
                st.warning("""
                **G·ª£i √Ω c·∫£i thi·ªán CV:**
                1. B·ªï sung th√™m chi ti·∫øt v·ªÅ kinh nghi·ªám l√†m vi·ªác
                2. Li·ªát k√™ ƒë·∫ßy ƒë·ªß c√°c k·ªπ nƒÉng chuy√™n m√¥n
                3. Th√™m th√¥ng tin v·ªÅ c√°c d·ª± √°n ƒë√£ th·ª±c hi·ªán
                4. B·ªï sung ch·ª©ng ch·ªâ ho·∫∑c th√†nh t√≠ch chuy√™n m√¥n
                5. M√¥ t·∫£ c·ª• th·ªÉ h∆°n v·ªÅ tr√°ch nhi·ªám v√† th√†nh t·ª±u trong c√¥ng vi·ªác
                """)
            
            # Ki·ªÉm tra c√°c ph·∫ßn
            missing_sections = check_missing_sections(content)
            st.subheader("Tips ƒë·ªÉ c·∫£i thi·ªán CV:")
            st.write("**C√°c ph·∫ßn trong CV c·ªßa b·∫°n:**")
            for section, status in missing_sections:
                st.write(f"- {section} {status}")
            
            # T√≠nh ƒëi·ªÉm
            total_sections = len(RECOMMENDED_SECTIONS)
            completed_sections = len([s for s, status in missing_sections if status == "‚úîÔ∏è"])
            score = (completed_sections / total_sections) * 100
            
            # Hi·ªÉn th·ªã ƒëi·ªÉm s·ªë
            st.subheader("ƒêi·ªÉm CV:")
            col1, col2, col3, col4, col5 = st.columns(5)

            with col1:
                st.metric("S·ªë k·ªπ nƒÉng", len(skills))

            with col2:
                st.metric("Kinh nghi·ªám", f"{years_exp} nƒÉm")

            with col3:
                st.metric("C·∫•p ƒë·ªô", level)

            with col4:
                st.metric("ƒêi·ªÉm CV", f"{int(score)}%")

            with col5:
                completed_sections = len([s for s, status in missing_sections if status == "‚úîÔ∏è"])
                st.metric("ƒê·ªô ho√†n thi·ªán", f"{int(completed_sections/len(RECOMMENDED_SECTIONS)*100)}%")
            
            # G·ª£i √Ω k·ªπ nƒÉng c·∫ßn c·∫£i thi·ªán
            st.subheader("G·ª£i √Ω k·ªπ nƒÉng c·∫ßn c·∫£i thi·ªán:")
            all_sample_skills = set(SKILLS_KEYWORDS)
            missing_skills = list(all_sample_skills - set(skills))
            if missing_skills:
                st.markdown(", ".join([f"`{skill}`" for skill in missing_skills[:10]]))
            else:
                st.success("B·∫°n ƒë√£ bao qu√°t t·∫•t c·∫£ c√°c k·ªπ nƒÉng quan tr·ªçng!")
            
            # L∆∞u d·ªØ li·ªáu CV
            cv_sections = extract_cv_sections(content)
            cv_data = {
                "cv_text": [content],
                "skills": [skills],
                "level": [level],
                "score": [score],
                "M·ª•c ti√™u ngh·ªÅ nghi·ªáp": [cv_sections["M·ª•c ti√™u ngh·ªÅ nghi·ªáp"]],
                "H·ªçc v·∫•n": [cv_sections["H·ªçc v·∫•n"]],
                "Kinh nghi·ªám l√†m vi·ªác": [cv_sections["Kinh nghi·ªám l√†m vi·ªác"]],
                "K·ªπ nƒÉng": [cv_sections["K·ªπ nƒÉng"]],
                "D·ª± √°n": [cv_sections["D·ª± √°n"]],
                "Ch·ª©ng ch·ªâ": [cv_sections["Ch·ª©ng ch·ªâ"]],
                "Th√†nh t√≠ch": [cv_sections["Th√†nh t√≠ch"]],
                "S·ªü th√≠ch": [cv_sections["S·ªü th√≠ch"]],
                "Lƒ©nh v·ª±c quan t√¢m": [cv_sections["Lƒ©nh v·ª±c quan t√¢m"]]
            }
            save_cv_data(cv_data)

            # Th√™m footer
            st.markdown("---")
            st.markdown("""
            <div style='text-align: center; color: #666;'>
            <p>Nhan Hoa with ‚ù§Ô∏è  | ¬© 2024 CV Analysis AI</p>
            </div>
            """, unsafe_allow_html=True)

            st.markdown("---")
            st.subheader("üìö T√†i li·ªáu h·ªØu √≠ch cho ph√°t tri·ªÉn ngh·ªÅ nghi·ªáp:")
            
            tab1, tab2 = st.tabs(["üé• Video h∆∞·ªõng d·∫´n", "üìù B√†i vi·∫øt tham kh·∫£o"])
            
            with tab1:
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("### ‚úçÔ∏è H∆∞·ªõng d·∫´n vi·∫øt CV")
                    st.video("https://www.youtube.com/watch?v=VI8AXBvmNLQ")
                    st.markdown("""
                    üéØ **Video h∆∞·ªõng d·∫´n vi·∫øt CV chuy√™n nghi·ªáp**
                    - C√°ch tr√¨nh b√†y CV hi·ªáu qu·∫£
                    - Nh·ªØng l·ªói c·∫ßn tr√°nh khi vi·∫øt CV
                    - Tips ƒë·ªÉ CV n·ªïi b·∫≠t
                    """)
                with col2:
                    st.markdown("### üé§ Tips ph·ªèng v·∫•n")
                    st.video("https://www.youtube.com/watch?v=qTUFr-1M6xY")
                    st.markdown("""
                    üí° **K·ªπ nƒÉng ph·ªèng v·∫•n c·∫ßn thi·∫øt**
                    - Chu·∫©n b·ªã tr∆∞·ªõc ph·ªèng v·∫•n
                    - Tr·∫£ l·ªùi c√¢u h·ªèi chuy√™n m√¥n
                    - T·∫°o ·∫•n t∆∞·ª£ng v·ªõi nh√† tuy·ªÉn d·ª•ng
                    """)
            
            with tab2:
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.markdown("""
                    ### üìë Vi·∫øt CV
                    - [H∆∞·ªõng d·∫´n vi·∫øt CV chi ti·∫øt](https://www.topcv.vn/huong-dan-viet-cv-chi-tiet-theo-nganh)
                    - [M·∫´u CV IT ƒë∆∞·ª£c ƒë√°nh gi√° cao](https://itviec.com/blog/huong-dan-viet-mau-cv-an-tuong-cho-it/)
                    - [CV theo chu·∫©n qu·ªëc t·∫ø](https://www.topcv.vn/mau-cv-tieng-anh/default)
                    """)
                with col2:
                    st.markdown("""
                    ### üé§ Ph·ªèng v·∫•n
                    - [Tips ph·ªèng v·∫•n IT](https://glints.com/vn/blog/kinh-nghiem-phong-van-it/)
                    - [C√¢u h·ªèi ph·ªèng v·∫•n Backend](https://glints.com/vn/blog/cau-hoi-phong-van-backend/)
                    - [C√¢u h·ªèi ph·ªèng v·∫•n Frontend](https://www.topcv.vn/cau-hoi-phong-van-front-end-developer-va-goi-y-tra-loi)
                    - [C√¢u h·ªèi ph·ªèng v·∫•n Tester, QA - QC](https://www.topcv.vn/nhung-cau-hoi-phong-van-tester)
                    """)
                with col3:
                    st.markdown("""
                    ### üí° Ph√°t tri·ªÉn b·∫£n th√¢n
                    - [L·ªô tr√¨nh ph√°t tri·ªÉn IT](https://roadmap.sh/)
                    - [K·ªπ nƒÉng m·ªÅm cho IT](https://aptechvietnam.com.vn/nhung-ky-nang-mem-can-thiet-cho-sinh-vien-cntt/)
                    - [T√†i nguy√™n h·ªçc IT mi·ªÖn ph√≠](https://free-for.dev/)
                    """)
elif role == "Admin":
    st.write("Xem c√°c d·ªØ li·ªáu CV ƒë√£ n·ªôp")
    
    # Ki·ªÉm tra ƒëƒÉng nh·∫≠p tr∆∞·ªõc khi hi·ªÉn th·ªã n·ªôi dung
    if admin_login():
        st.header("Admin Dashboard")
        
        # Logout button
        if st.sidebar.button("Logout"):
            st.session_state.logged_in = False
            st.rerun()
        
        # Ch·ªâ hi·ªÉn th·ªã n·ªôi dung khi ƒë√£ ƒëƒÉng nh·∫≠p th√†nh c√¥ng
        if st.session_state.logged_in:
            # Load CV data
            df = load_cv_data()
            
            if not df.empty:
                total_users = df.shape[0]
                st.write(f"Total CVs processed: {total_users}")
                
                # Statistics
                st.subheader("üìä Th·ªëng k√™ t·ªïng quan")
                col1, col2 = st.columns(2)
                
                with col1:
                    level_counts = pd.Series({
                        'Fresher': random.randint(20, 30),
                        'Junior': random.randint(15, 25),
                        'Middle': random.randint(10, 20),
                        'Senior': random.randint(5, 15)
                    })
                    
                    fig1 = px.pie(
                        values=level_counts.values,
                        names=level_counts.index,
                        title='Ph√¢n b·ªë c·∫•p ƒë·ªô kinh nghi·ªám c·ªßa ·ª©ng vi√™n'
                    )
                    st.plotly_chart(fig1)
                
                with col2:
                    score_counts = pd.Series({
                        '0-20': random.randint(5, 10),
                        '21-40': random.randint(10, 15),
                        '41-60': random.randint(15, 20),
                        '61-80': random.randint(20, 25),
                        '81-100': random.randint(25, 30)
                    })
                    fig2 = px.pie(
                        values=score_counts.values,
                        names=score_counts.index,
                        title='Ph√¢n b·ªë ƒëi·ªÉm CV',
                        color_discrete_sequence=['#FF9F1C', '#2EC4B6', '#665191', '#FF69B4', '#5e60ce']
                    )
                    st.plotly_chart(fig2)
                # Detailed data table
                st.subheader("üìã B·∫£ng d·ªØ li·ªáu chi ti·∫øt")
                st.dataframe(df)
            else:
                st.warning("No CV data found.")
# Th√™m footer chung cho c·∫£ User v√† Admin
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
<p>Nhan Hoa with ‚ù§Ô∏è  | ¬© 2024 CV Analysis AI</p>
</div>
""", unsafe_allow_html=True)
